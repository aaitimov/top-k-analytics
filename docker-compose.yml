services:
  kafka:
    image: bitnami/kafka:4.0.0
    ports:
      - "9094:9094"
    environment:
      - KAFKA_CFG_NODE_ID=0
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:9093
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:9094
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,EXTERNAL://localhost:9094
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=false
      - KAFKA_CFG_LOG_RETENTION_HOURS=24
      - KAFKA_CFG_LOG_RETENTION_CHECK_INTERVAL_MS=300000
    volumes:
      - kafka-data:/bitnami/kafka
    healthcheck:
      test: [ "CMD-SHELL", "kafka-topics.sh --bootstrap-server localhost:9092 --list > /dev/null" ]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  kafka-init:
    image: bitnami/kafka:4.0.0
    depends_on:
      kafka:
        condition: service_healthy
    entrypoint:
      - "/bin/bash"
      - "-c"
    command: >
      "/opt/bitnami/kafka/bin/kafka-topics.sh \\
        --bootstrap-server kafka:9092 \\
        --create --if-not-exists \\
        --topic song-play-events \\
        --partitions 4 \\
        --replication-factor 1"     
  event-generator:
    build:
      context: ./event-generator
    depends_on:
      kafka:
        condition: service_healthy
      kafka-init:
        condition: service_completed_successfully
    environment:
      KAFKA_TOPIC: "song-play-events"
      KAFKA_BOOTSTRAP_SERVERS: "kafka:9092"
      PRODUCER_THREADS: "2"
      BATCH_SIZE: "100"
    restart: unless-stopped

  kafdrop:
    image: obsidiandynamics/kafdrop:4.2.0
    ports:
      - "9000:9000"
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      KAFKA_BROKERCONNECT: "kafka:9092"
      JVM_OPTS: "-Xms32M -Xmx128M"
      SERVER_SERVLET_CONTEXTPATH: "/"
    restart: unless-stopped

  datamart:
    image: postgres:17-alpine
    restart: unless-stopped
    environment:
      POSTGRES_USER: flink
      POSTGRES_PASSWORD: flink
      POSTGRES_DB: datamart
    ports:
      - "15432:5432"
    volumes:
      - datamart-data:/var/lib/postgresql/data
      - ./datamart/init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U flink -d datamart" ]
      interval: 10s
      timeout: 5s
      retries: 5

  stream-processor-jobmanager:
    build:
      context: ./stream-processor
    ports:
      - "18081:8081"
    command: "standalone-job --pyFiles /app -pym app.main"
    depends_on:
      kafka:
        condition: service_healthy
      datamart:
        condition: service_healthy
    volumes:
      - flink-checkpoints-jobmanager:/flink-checkpoints
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: stream-processor-jobmanager
        parallelism.default: 1
        state.checkpoints.dir: file:///flink-checkpoints
      - KAFKA_TOPIC=song-play-events
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - DB_HOST=datamart
      - DB_PORT=5432
      - DB_SCHEMA=datamart
      - DB_USER=flink
      - DB_PASSWORD=flink
    restart: unless-stopped

  stream-processor-taskmanager:
    build:
      context: ./stream-processor
    depends_on:
      - stream-processor-jobmanager
    command: taskmanager
    scale: 1
    volumes:
      - flink-checkpoints-taskmanager:/flink-checkpoints
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: stream-processor-jobmanager
        taskmanager.numberOfTaskSlots: 1
        parallelism.default: 1
        state.checkpoints.dir: file:///flink-checkpoints
    restart: unless-stopped

volumes:
  kafka-data:
  datamart-data:
  flink-checkpoints-jobmanager:
  flink-checkpoints-taskmanager:
